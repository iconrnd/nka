{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e5059a-8091-4304-bb36-4bf71859a5d1",
   "metadata": {},
   "source": [
    "# Training YOLOv8\n",
    "### Example directly applied from https://keras.io/examples/vision/yolov8/\n",
    "### Modified from XMP to TXT label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7107a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "% 20% for validation\n",
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e378f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One class detection\n",
    "class_ids = [\n",
    "    \"apple\",\n",
    "]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc7bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc02649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apple'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4615bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to images and annotations\n",
    "path_images = \"./export/export/train/images\"\n",
    "path_annot = \"./export/export/train/labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098bff0c-f669-4862-802b-148ccbc2448e",
   "metadata": {},
   "source": [
    "## Sorting image and annotation files lists\n",
    "## After that these two lists will be in sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5fc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all TXT file paths in path_annot and sort them\n",
    "txt_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".txt\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81263396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all PNG image file paths in path_images and sort them\n",
    "image_paths = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".png\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994ed7e-c564-447f-9c6c-33c7b72a08ee",
   "metadata": {},
   "source": [
    "## Extracting bounding box and class data from TXT annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "229dbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(txt_file):\n",
    "    df = pd.read_csv(txt_file, sep=' ', names=['id', 'xmin', 'xmax', 'ymin', 'ymax'])\n",
    "    boxes = [list(df[['xmin', 'xmax', 'ymin', 'ymax']].iloc[i]) for i in range(len(df))]\n",
    "    # Auxilliary step, resizing boxes for the particular used image format\n",
    "    boxes = [[640 * boxes[i][0],  640 * boxes[i][1] + 5,  640 * boxes[i][2],  640 * boxes[i][3]]  for i in range(len(df))]\n",
    "    classes = list(df['id'])\n",
    "    \n",
    "    return boxes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecc2c8-eb18-4ee0-b642-4794469861fa",
   "metadata": {},
   "source": [
    "## Sample file and parsing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0ff905-7354-4619-8b56-2ee7f328142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./export/export/train/labels/data-1.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ff89ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[142.14458562091457, 147.14458562091457, 36.864, 16.852114285714304],\n",
       "  [224.06458562091456,\n",
       "   229.06458562091456,\n",
       "   36.40888888888883,\n",
       "   20.831085714285695],\n",
       "  [0.440386928104576,\n",
       "   5.4403869281045765,\n",
       "   25.164967320261376,\n",
       "   16.048059159663808],\n",
       "  [144.51116339869313,\n",
       "   149.51116339869313,\n",
       "   30.09623006535936,\n",
       "   15.880088739495807],\n",
       "  [226.58978300653632,\n",
       "   231.58978300653632,\n",
       "   37.265568627450946,\n",
       "   18.526311260504126],\n",
       "  [419.9223215686278, 424.9223215686278, 39.25734901960768, 20.90543327731085],\n",
       "  [457.2307241830067,\n",
       "   462.2307241830067,\n",
       "   27.842091503267902,\n",
       "   15.607481008403328],\n",
       "  [571.4181019607847, 576.4181019607847, 34.94717908496717, 21.33224336134445],\n",
       "  [578.1483921568627,\n",
       "   583.1483921568627,\n",
       "   37.886661437908415,\n",
       "   15.789219495798273],\n",
       "  [615.7084444444442,\n",
       "   620.7084444444442,\n",
       "   24.169077124182913,\n",
       "   22.172095462184767]],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_annotation(txt_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78123f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = []\n",
    "classes = []\n",
    "for txt_file in tqdm(txt_files):\n",
    "    boxes, class_ids = parse_annotation(txt_file)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f039e-ef01-4870-a766-e76f5a763ac0",
   "metadata": {},
   "source": [
    "### Representing image data as ragged tensors for efficiency \n",
    "### (there are differing numbers of cases on each photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc5f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 11:11:39.562298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.565973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.566070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.568071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.568186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.568260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.612560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.612675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.612746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 11:11:39.612814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3908 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86aeda-f573-4be6-9ea9-3b06443f1e63",
   "metadata": {},
   "source": [
    "## Creating dataset - at this stage images as paths only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d7a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "350b248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of validation samples\n",
    "num_val = int(len(txt_files) * SPLIT_RATIO)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "val_data = data.take(num_val)\n",
    "train_data = data.skip(num_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab099c9-385e-4c3d-9be9-da3f052d96f5",
   "metadata": {},
   "source": [
    "## Data processing routines for dataset data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eb81ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae47cec-d372-4b01-ba53-2076f24ac651",
   "metadata": {},
   "source": [
    "## Data augmentation and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccfcf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8204f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc5624-9e3c-45d2-a8ea-e98446fcf4e8",
   "metadata": {},
   "source": [
    "### For validation dataset only resizing, no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "384b3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(0.75, 1.3),\n",
    "    bounding_box_format=\"xyxy\",\n",
    ")\n",
    "\n",
    "val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(BATCH_SIZE * 4)\n",
    "val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8b4b6-e55b-476a-9041-b8d956f93605",
   "metadata": {},
   "source": [
    "## Tranforming dataset to training-ready form with features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d0055c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422f45b-1aa7-41f1-9f14-448b3eedef3b",
   "metadata": {},
   "source": [
    "## Small backbone network from COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b604410",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone_coco\"  # We will use yolov8 small backbone with coco weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e355e1c-0e4d-44f0-a5df-1ec41ed71e28",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "### fpn_depth specifies Feature Pyramid Network depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc591fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bbf789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9163654-a008-4124-bb4f-0541a7198556",
   "metadata": {},
   "source": [
    "## Callback for preservig better models (lib broken at this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2b1d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "#    def __init__(self, data, save_path):\n",
    "#        super().__init__()\n",
    "#        self.data = data\n",
    "#        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "#            bounding_box_format=\"xyxy\",\n",
    "#            evaluate_freq=1e9,\n",
    "#        )\n",
    "\n",
    "#        self.save_path = save_path\n",
    "#        self.best_map = -1.0\n",
    "\n",
    "#    def on_epoch_end(self, epoch, logs):\n",
    "#        self.metrics.reset_state()\n",
    "#        for batch in self.data:\n",
    "#            images, y_true = batch[0], batch[1]\n",
    "#            y_pred = self.model.predict(images, verbose=0)\n",
    "#            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "#        metrics = self.metrics.result(force=True)\n",
    "#        logs.update(metrics)\n",
    "\n",
    "#        current_map = metrics[\"MaP\"]\n",
    "#        if current_map > self.best_map:\n",
    "#            self.best_map = current_map\n",
    "#            self.model.save(self.save_path)  # Save the model when mAP improves\n",
    "\n",
    "#        return logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,\n",
    "    # COCOMetric callback is broken as of now \n",
    "    #callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"model.h5\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4db3b5-72b2-4461-8119-99e7010d3341",
   "metadata": {},
   "source": [
    "## Prediction visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0713fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(model, dataset, bounding_box_format):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    y_pred = bounding_box.to_ragged(y_pred)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "visualize_detections(yolo, dataset=val_ds, bounding_box_format=\"xyxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e45c82-39db-4f47-a492-a8b3c014933b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
